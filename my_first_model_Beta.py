# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gxETxY-vge7g8Krw2d2GPD_l8duQMzkC

## **Reading the file**
"""



"""# **Import**"""

# Basic Libraries
import pandas as pd
import numpy as np

# Data Preprocessing
from sklearn.model_selection import train_test_split

# XGBoost Regressor
from xgboost import XGBRegressor

# Model Evaluation
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv("Chennai houseing sale.csv")
df.head()

"""# **Modelling**

### Training and Testing
"""

# Select only numeric features
X = df[['INT_SQFT',
        'DIST_MAINROAD',
        'N_BEDROOM',
        'N_BATHROOM',
        'N_ROOM',
        'QS_OVERALL']]

y = df['SALES_PRICE']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = XGBRegressor(random_state=42)

#Training model
model.fit(X_train, y_train)

"""## **Prediction**"""

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.4f}")

"""## **Graph**"""

import matplotlib.pyplot as plt

# Get feature importance scores
importance = model.feature_importances_

# Plot
plt.barh(X.columns, importance)
plt.xlabel("Feature Importance")
plt.title("XGBoost Feature Importance")
plt.show()

"""# New Sample House"""

# Example: new house data as a dict (with only numeric features here)
new_house = {
    'INT_SQFT': 1200,
    'DIST_MAINROAD': 5.5,
    'N_BEDROOM': 3,
    'N_BATHROOM': 2,
    'N_ROOM': 5,
    'QS_OVERALL': 7
}

new_df = pd.DataFrame([new_house])

predicted_price = model.predict(new_df)

formatted_price = "₹{:,.2f}".format(predicted_price[0])
print(formatted_price)

print(f"Predicted Price: ₹{predicted_price[0]:,.2f}")

